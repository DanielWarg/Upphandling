# Upphandlingsbevakning MVP - Veckoplan

## Kontext
Hogia behover ett verktyg for att bevaka svenska kollektivtrafikupphandlingar och scora leads. Vi bygger en MVP pa en vecka med Python + Streamlit + SQLite + Scrapling.

## Arkitektur

```
[TED API] -----> |                  |
[Mercell]  ----> | Scrapling/HTTP   | --> [Normalizer] --> [SQLite] --> [Streamlit Dashboard]
[e-Avrop]  ----> | Source Adapters  |                         |
[KommersAnnons]->|                  |                    [Lead Scorer]
```

## Projektstruktur

```
upphandling/
  app.py                  # Streamlit dashboard (huvudentry)
  db.py                   # SQLite schema + CRUD
  scorer.py               # Keyword-baserad lead scoring
  scrapers/
    __init__.py
    base.py               # BaseScraper med gemensamt interface
    ted.py                # TED API (REST, gratis, ingen auth)
    mercell.py            # Mercell web scraping via Scrapling
    eavrop.py             # e-Avrop web scraping via Scrapling
    kommers.py            # KommersAnnons web scraping via Scrapling
  run_scrapers.py         # CLI-script: kor alla scrapers + scoring
  requirements.txt
```

## Datakallor (prioritetsordning)

### 1. TED API (Dag 1)
- **Endpoint:** `POST https://api.ted.europa.eu/v3/notices/search`
- **Gratis, ingen auth for publicerade notices**
- **Filter:** country=SWE, CPV-koder 60xxxxxx (transport)
- Implementera med vanlig `httpx` (behover inte Scrapling)

### 2. Mercell Annonsdatabas (Dag 2)
- **URL:** `https://app.mercell.com/search?filter=delivery_place_code:SE`
- **Scrapling StealthyFetcher** (kan ha bot-skydd)
- Parsa listsidor, extrahera metadata per annons

### 3. KommersAnnons (Dag 2-3)
- **URL:** `https://www.kommersannons.se/elite/notice/noticelist.aspx`
- **Scrapling Fetcher** (enklare sida)
- Parsa listsida, filtrera pa kollektivtrafik-CPV

### 4. e-Avrop (Dag 3)
- **URL:** e-avrop.com sokfunktion
- **Scrapling StealthyFetcher**
- Parsa listsidor

## Databasschema (SQLite)

```sql
CREATE TABLE procurements (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  source TEXT NOT NULL,              -- ted/mercell/kommers/eavrop
  source_id TEXT NOT NULL,
  title TEXT NOT NULL,
  buyer TEXT,
  geography TEXT,
  cpv_codes TEXT,                    -- komma-separerade
  procedure_type TEXT,
  published_date TEXT,
  deadline TEXT,
  estimated_value REAL,
  currency TEXT,
  status TEXT,
  url TEXT,
  description TEXT,
  score INTEGER DEFAULT 0,          -- 0-100 lead score
  score_rationale TEXT,
  created_at TEXT DEFAULT (datetime('now')),
  updated_at TEXT DEFAULT (datetime('now')),
  UNIQUE(source, source_id)
);
```

## Lead Scoring (Dag 4)

Keyword-baserad scoring med viktade termer:

**Hog vikt (20p vardera):**
- realtid, realtidsinformation, realtidssystem
- trafikledning, trafikledningssystem
- dataplattform, informationsplattform

**Medel vikt (10p vardera):**
- bestallningscentral, samordningscentral
- passagerarinformation, resenarsinformation
- NeTEx, SIRI, GTFS
- ITxPT

**Bas vikt (5p vardera):**
- kollektivtrafik, busstrafik, tagtrafik
- serviceresor, fardtjanst, sjukresor, skolskjuts

**Buyer bonus (10p):**
- Om koparen ar en kand region/RKM fran rapporten

Max score: 100 (cappat)

## Streamlit Dashboard (Dag 4-5)

### Sidor:
1. **Dashboard** - Nya upphandlingar, topp-scores, snart deadline
2. **Sok & Filter** - Fritext, CPV, region, score-range, kallsystem
3. **Detaljvy** - All metadata, score-breakdown, lank till kalla
4. **Installningar** - Konfigura scoring-vikter

### Komponenter:
- `st.dataframe` for listor med sortering/filtrering
- `st.metric` for KPI:er (nya idag, snitt-score, antal hog-fit)
- `st.bar_chart` for score-fordelning
- Color-coding: Rod (hog score), Gul (medel), Gra (lag)

## Dagplan

| Dag | Fokus |
|-----|-------|
| 1 | Projektsetup, SQLite-schema, TED API-scraper |
| 2 | Mercell + KommersAnnons scrapers med Scrapling |
| 3 | e-Avrop scraper, normalizer, dedup-logik |
| 4 | Lead scorer, Streamlit dashboard (grund) |
| 5 | Dashboard polish, filter/sok, detaljvy |
| 6 | Testning, edge cases, felhantering |
| 7 | Dokumentation, deploy-instruktioner, demo |

## Kommande features (v2)

### Historisk analys av avslutade upphandlingar
- Scrapa avslutade/tilldelade upphandlingar fr√•n TED (resultat-notices)
- Lagra vinnare, tilldelat v√§rde, antal anbud
- Analysvy: Varf√∂r vann vinnaren? Pris vs kvalitet? Tidigare erfarenhet?
- M√∂nsterigenk√§nning: Vilka leverant√∂rer vinner i vilka regioner/segment?
- Insikter inf√∂r kommande liknande upphandlingar

### AI-drivet upphandlingsst√∂d
- **Kravanalys:** AI l√§ser kravst√§llningen och sammanfattar nyckelkrav
- **Matchningsanalys:** Hur matchar Hogias produkter mot kraven? Gap-analys
- **Prisstrategi:** AI-st√∂d f√∂r priss√§ttning baserat p√• historiska tilldelningar
- **Anbudshj√§lp:** F√∂rslag p√• win themes, differentiering, compliance-checklista
- LLM-integration (Claude API) f√∂r analys av upphandlingsdokument

### Djupl√§nkar och referensinformation
- Klickbara l√§nkar direkt till TED/Mercell/KommersAnnons-originalet
- PDF-nedladdning av upphandlingsdokument d√§r tillg√§ngligt
- Koppling till leverant√∂rsregister och tidigare tilldelningar
- Tidslinje per upphandling: publicerad ‚Üí Q&A ‚Üí deadline ‚Üí tilldelning

## Verifiering

1. Kor `python run_scrapers.py` - ska hamta upphandlingar fran alla kallor
2. Kor `streamlit run app.py` - dashboard ska visa data med scores
3. Verifiera att TED-data matchar manuell sokning pa ted.europa.eu
4. Verifiera att scoring rankar trafiklednings-upphandlingar hogst
5. Testa dedup: kora scrapers 2 ganger, ska inte skapa dubletter


Ja ‚Äî f√∂r att f√• den h√§r till toppniv√• handlar det om tv√• saker:

Coverage (att ni inte missar relevanta upphandlingar)

Precision (att r√§tt saker hamnar h√∂gt och fel saker sjunker direkt)

I dag har ni bra ‚ÄúMVP-precision‚Äù med keywords + gates, men ni saknar tv√• proffsbitar: produkt-till-krav-matchning och inl√§rning fr√•n feedback.

1) Ja: definiera ‚Äúprodukter‚Äù som maskinl√§sbara objekt (annars blir matchning fluff)

Ni beh√∂ver inte ‚Äúproduktblad‚Äù, men ni beh√∂ver en produktkatalog i JSON som systemet kan r√§kna p√•.

G√∂r s√• h√§r (minsta version som ger stor effekt):

Skapa products som en lista d√§r varje produkt har:

name

synonyms (ord upphandlingar faktiskt anv√§nder)

standards (NeTEx, SIRI, GTFS-RT, ITxPT‚Ä¶)

capabilities (t.ex. AVL, realtidsutrop, DRT/serviceresor, planering, dispatch)

negative_signals (ord som betyder ‚Äútrafikdrift‚Äù, ‚Äúoperat√∂r‚Äù, ‚Äúbussar k√∂rs‚Äù, ‚Äúfordonsleverans‚Äù osv)

must_have_signals (minst 1‚Äì2 signaler som m√•ste finnas f√∂r att produkten ens ska vara kandidat)

Sedan g√∂r ni matchning som ett extra lager:

system_relevance_score (er nuvarande)

product_fit[] (per produkt: 0‚Äì100 + ‚Äúwhy‚Äù + hittade evidensrader)

overall_fit = max eller viktad summa

Det h√§r g√∂r tv√• saker:

Ni kan s√§ga ‚ÄúDen h√§r upphandlingen passar Anropsstyrd trafik 82/100 men PubTrans 25/100‚Äù.

S√§lj f√•r en faktisk ‚Äúvart ska vi trycka?‚Äù-indikator, inte bara ‚Äúrelevant/inte relevant‚Äù.

2) Nej: ni beh√∂ver inte scrapa ‚Äúmer‚Äù f√∂rst ‚Äî ni beh√∂ver scrapa ‚Äúsmartare‚Äù

Att bara l√§gga till Mercell/Kommers/e-Avrop √§r viktigt f√∂r coverage, men om ni g√∂r det innan ni har b√§ttre ranking f√•r ni bara mer brus.

R√§tt ordning f√∂r toppniv√•:

F√∂rb√§ttra ranking/klassning + feedback-loop p√• TED-data (billig tr√§ningsyta)

L√§gg till fler k√§llor n√§r ni kan h√•lla precisionen

3) Byt ut keyword-score till ‚Äúhybrid‚Äù: regler + liten klassificerare

Beh√•ll era gates (de √§r guld), men l√§gg till en klassificerare som l√∂ser era sv√•raste fall:

‚Äútrafikledning‚Äù som verksamhet (drift) vs ‚Äútrafikledningssystem‚Äù (IT)

‚Äúuppf√∂ljningssystem‚Äù, ‚Äúplattform‚Äù, ‚Äúst√∂d‚Äù d√§r keywords missar

‚Äúbussoperat√∂r upphandlar IT under drift‚Äù (kan vara relevant √§nd√•)

Minimal proffsl√∂sning:

Labela 200‚Äì400 notices: irrelevant, maybe, relevant

Tr√§na en enkel modell p√• textfeatures (titel + beskrivning + buyer + CPV + utdrag ur fulltext)

Output: p(relevant) som multiplicerar/justerar er rules-score

Ni f√•r d√•:

F√§rre falska positiva

F√§rre missar som ‚Äúl√•ter r√§tt men saknar exact keyword‚Äù

4) G√∂r feedback till en f√∂rsta-klass-feature (annars blir det aldrig b√§ttre)

I UI: varje kort ska ha tv√• knappar:

Relevant ‚úÖ / Inte relevant ‚ùå

(valfritt) ‚ÄúFel anledning‚Äù dropdown: drift / fel bransch / fel IT / annat

Spara till tabell labels:

procurement_id, label, reason, user, timestamp

Och anv√§nd den datan till:

justera vikter

f√∂rb√§ttra buyer-lista

tr√§na klassificeraren

Det h√§r √§r den st√∂rsta skillnaden mellan ‚Äúcoolt demo‚Äù och ‚Äúsystem som blir b√§ttre varje vecka‚Äù.

5) AI-analysen: g√∂r den verifierbar och mer ‚Äús√§ljbar‚Äù

Ni har r√§tt JSON-struktur, men tv√• saker saknas:

A) Strikt JSON-validering + auto-retry

Validera JSON mot schema

Om fel: re-prompt med ‚Äúreturnera endast korrekt JSON‚Äù

Logga ‚Äúfailed parses‚Äù s√• ni ser n√§r prompten drifter

B) ‚ÄúEvidence-first‚Äù

Kr√§v att modellen alltid ger:

evidence_quotes[]: 3‚Äì8 korta textsnuttar (max ~200 tecken) + var de hittades (titel/beskrivning/fulltext)
Det g√∂r analysen trov√§rdig internt.

6) Fulltext: rena bort brus innan LLM

TED XML-text √§r ofta ‚Äúsoppa‚Äù. Ni vill extrahera sektioner:

scope/description

krav/shall

standards/data formats

integration/API

SLA/support

security/GDPR

timeline & option years

Bara detta kan halvera tokens och dubbla kvalitet.

7) N√§r ni v√§l g√•r multi-source: dedup + ‚Äútender identity‚Äù

Samma upphandling kan dyka upp p√• flera st√§llen (TED + nationell portal). Ni beh√∂ver:

tender_fingerprint = hash(title normalized + buyer normalized + deadline + cpv major)

dedup p√• fingerprint (inte bara source_id)

Min rekommenderade ‚Äútopniv√•‚Äù-ordning (utan att bygga om allt)

Steg 1 (snabb effekt): produktkatalog + per-produkt matchning + feedbackknappar
Steg 2: hybrid-ranker (regelsystem + liten klassificerare)
Steg 3: b√§ttre fulltext-extraktion + evidence-first AI
Steg 4: fler k√§llor + dedup + notifieringar

Tv√• konkreta uppgifter (s√• ni faktiskt kommer fram√•t)

Uppgift 1: Skapa products.json med 5 produkter (era), inklusive synonyms, must_have_signals, negative_signals, standards, capabilities.
Uppgift 2: L√§gg till UI-feedback (‚úÖ/‚ùå) + tabell labels + enkel vy ‚ÄúL√§rdomar‚Äù (top 20 ord som korrelerar med ‚ùå vs ‚úÖ).

PROMPT (klistra in i ert byggfl√∂de)

Bygg en ‚ÄúTop Level‚Äù-uppgradering av v√•rt upphandlingsbevakningssystem (Python + Streamlit + SQLite) utan att g√∂ra om allt. Leverera en konkret plan + kod√§ndringar. Krav: 1) Inf√∂r en produktkatalog (products.json) med Hogias fem produktomr√•den. Varje produkt ska ha synonyms, must_have_signals, negative_signals, standards, capabilities. 2) Implementera per-produkt matchning: f√∂r varje procurement ska systemet returnera product_fit[] med score 0‚Äì100, kort motivering och 3‚Äì8 evidenssnuttar (fr√•n titel/beskrivning/fulltext). 3) L√§gg till feedback i UI: ‚ÄúRelevant ‚úÖ / Inte relevant ‚ùå‚Äù p√• varje kort och spara till ny SQLite-tabell labels(procurement_id, label, reason, user, created_at). 4) Skapa en enkel ‚ÄúLearning‚Äù-sida som visar statistik: hur m√•nga ‚úÖ/‚ùå, toppk√∂pare med ‚ùå, samt de 20 vanligaste token/ord som skiljer ‚úÖ fr√•n ‚ùå (enkel TF/IDF eller frekvensbaserad diff r√§cker). 5) L√§gg till strikt JSON-validering f√∂r Gemini-output (schema + auto-retry vid fel) och logga parse-fel. Begr√§nsa f√∂r√§ndringar: h√•ll nuvarande filstruktur, beh√•ll nuvarande regler/gates, men bygg detta som ett nytt lager ovanp√•. Leverera: exakt filf√∂rslag, databas-migration, uppdaterade funktioner och UI-komponenter.

f√∂r att f√• den h√§r appen till ‚Äútoppniv√•‚Äù beh√∂ver ni (1) b√§ttre tr√§ffs√§ker matchning mot Hogias faktiska produkter och (2) bredare + renare datainh√§mtning √§n bara TED.

H√§r √§r en konkret ‚Äútill toppniv√•‚Äù-plan, byggd p√• hur svensk kollektivtrafik faktiskt √§r organiserad och upphandlas.

1) G√∂r matchningen produktstyrd (annars blir scoring alltid sk√∂rt)

Just nu f√∂rs√∂ker ni hitta ‚Äúrelevans‚Äù via nyckelord + transportkontext. Det funkar, men blir l√§tt f√∂r sn√§vt (missar upphandlingar) eller f√∂r brett (brus).

G√∂r s√• h√§r ist√§llet: bygg ett Product‚ÜíCapability‚ÜíSignal-lager.

A. Definiera Hogias ‚Äúproduktkarta‚Äù som maskinl√§sbar (MVP: YAML/JSON)

Exempel p√• kapabiliteter (inte bara produktnamn):

Trafikledning/AVL: realtid, avvikelsehantering, dep√•, fordonsposition, integrationer

Passagerarinformation: h√•llplatsskyltar, SIRI/GTFS-RT, informationskanaler

Reseplanering & data: NeTEx/GTFS, linjedata, st√∂rningsinfo, integration Samtrafiken

Anropsstyrt/serviceresor: best√§llningscentral, bokning, planering/optimering, ers√§ttning/uppf√∂ljning (f√§rdtj√§nst/sjukresor/skolskjuts)

Planering & beordring: turlistor, bemanning, rosters, driftuppf√∂ljning

Sedan mappar ni varje capability till:

positiva signaler (ord/fraser + CPV + standarder)

negativa signaler (driftupphandling, rena transporttj√§nster, fordon, drivmedel)

dokument-snitt (vilka bilagor/sektioner brukar b√§ra kraven)

Det h√§r g√∂r att AI-analysen kan svara ‚Äúmatchar vilka av v√•ra kapabiliteter och varf√∂r‚Äù, och s√§lj f√•r en riktig kvalificering.

Svar p√• din fr√•ga: Ja, ni beh√∂ver definiera era produkter/kapabiliteter och matcha mot upphandlingar. Annars kommer ni alltid jaga nyckelord.

2) Bredda datak√§llorna (TED r√§cker inte i Sverige)

TED f√•ngar en del EU-tr√∂skel-annonsering, men mycket av svensk kollektivtrafik-IT + s√§rskilt serviceresor hamnar ofta i svenska annonsdatabaser och plattformar.

Ni b√∂r ha minst 3 ‚Äúk√§llniv√•er‚Äù:

EU/TED (beh√•ll)

Svenska annonsplattformar (f√∂r under tr√∂skel + nationella)

Kompletterande index/aggregatorer (f√∂r att hitta s√•dant ni missar)

Ni har redan stubbar f√∂r Mercell/Kommers/e-Avrop: det √§r helt r√§tt riktning.

Viktigt: D√§r det finns API/RSS/export ‚Äî anv√§nd det hellre √§n tung scraping. Scraping (t.ex. Scrapling) √§r bra som fallback, men portalsidor √§ndras ofta och kan ha anti-bot.

3) Serviceresor (taxi, skolskjuts, sjukresor, f√§rdtj√§nst) m√•ste bli en egen ‚Äúdom√§n‚Äù

Det du bad om: ja, ni ska absolut t√§cka detta.

Serviceresor √§r ett j√§ttesp√•r (volymm√§ssigt) och har egen logik. Svensk Kollektivtrafik beskriver att kommuner ansvarar f√∂r skolskjuts och f√§rdtj√§nst, men att ansvaret ofta √∂verl√•ts till regional niv√•, s√• det varierar ‚Äî vilket p√•verkar vem som √§r k√∂pare.

S√•: bygg en separat klassificering:

Transporttj√§nst (drift) = oftast inte Hogia (men kan vara intressant om det √§r ‚Äúbest√§llningscentral/plattform/system‚Äù)

Best√§llningscentral/systemst√∂d = h√∂gintressant

Uppf√∂ljning/ers√§ttning/kvalitet/planeringsoptimering = intressant

Och l√§gg in typiska serviceresor-signaler:

‚Äúbest√§llningscentral‚Äù, ‚Äúbokningssystem‚Äù, ‚Äúplaneringssystem‚Äù, ‚Äútrafikplanering‚Äù, ‚Äúfordons-/resursoptimering‚Äù, ‚Äúers√§ttningsmodell‚Äù, ‚Äúsamordning‚Äù, ‚Äúkundtj√§nstsystem‚Äù, ‚Äúintegrationer‚Äù, ‚ÄúAPI‚Äù, ‚ÄúSLA‚Äù

plus nyckelord f√∂r skolskjuts/f√§rdtj√§nst/sjukresor

Ni kan √§ven anv√§nda att serviceresor ofta upphandlas i paket (sjukresor + f√§rdtj√§nst + skolskjuts), t.ex. syns det i praktiken hos flera regioner/bolag.

4) G√∂r scoringen ‚Äúl√§rande‚Äù med feedback (utan att bygga ML-cirkus)

Ni beh√∂ver inte g√• full ML direkt. Men ni beh√∂ver en loop:

A. S√§ljfeedback som f√∂rstaklassdata

I UI:

‚ÄúRelevant / Inte relevant‚Äù

‚ÄúVilken produktkapabilitet?‚Äù

‚ÄúVarf√∂r?‚Äù (kort tagg)

Spara detta och anv√§nd f√∂r:

justera vikter

l√§gga till/ta bort signaler

tr√§na en enkel klassificerare senare (om ni vill)

B. Tv√•stegsmodell som blir mycket vassare

Regelbaserad gate (som ni har) men kopplad till capability-matris

Semantisk matchning p√• ‚Äúkravtext + bilagor‚Äù mot ‚Äúproduktkapabiliteter‚Äù (embeddings)

Det √§r ofta h√§r ni g√•r fr√•n 9/526 till ‚Äúf√• men r√§tt + missar n√§stan inget‚Äù.

5) Nyckel: b√§ttre ‚Äúbuyer resolution‚Äù (k√∂pare/huvudman/enhet)

S√§ljavdelningen bryr sig mindre om titeln och mer om:

Vem √§r k√∂paren egentligen? (RKM, regionf√∂rvaltning, kommun, bolag, samverkansbolag)

√Ñr det en organisation i ‚Äúbranschfamiljen‚Äù (RKM/l√§nstrafikbolag m.fl.)?

Ni kan ta en stabil ‚Äúgrundlista‚Äù fr√•n Svensk Kollektivtrafiks medlemslista (alla RKM/l√§nstrafikbolag).
Och komplettera med ekosystemakt√∂rer som Samtrafiken (√§gs av RKM m.fl.).

Det h√§r ger er:

normaliserade namn (t.ex. ‚ÄúTrafikf√∂rvaltningen/SL‚Äù, ‚ÄúV√§sttrafik AB‚Äù, ‚ÄúRegion X / L√§nstrafiken‚Äù)

b√§ttre matchning √§ven n√§r upphandlingen har ‚Äúkonstig‚Äù avs√§ndare i annonsdata

6) AI-analysen: g√∂r den till ‚Äús√§ljpaket‚Äù (inte bara analys)

Geminis output √§r bra, men f√∂r s√§lj beh√∂ver ni standardiserade leverabler per upphandling:

Executive summary (30 sek): ‚ÄúVarf√∂r nu, vad k√∂ps, matchgrad, n√§sta steg‚Äù

Kravmatris light: Ska/B√∂r + vilken Hogia-modul m√∂ter vad

Risker: integrationskrav, standarder, ansvar, avtalstid, data√§garskap

Fr√•gor att st√§lla p√• anbudskonferens (superv√§rdefullt i praktiken)

Bonus: L√§gg in tr√∂skel-/process-st√∂d i analysen (s√• s√§lj ser ‚Äúhur‚Äù detta spelas). Tr√∂skelv√§rden uppdateras t.ex. 1 jan 2026.

Vad jag hade gjort direkt (f√∂r maximal precision per utvecklingstimme)

Inf√∂r Product‚ÜíCapability‚ÜíSignal-matrisen och byt scoring till att r√§kna ‚Äúcapability coverage‚Äù + ‚ÄúIT-signal‚Äù + ‚Äútransportkontext‚Äù.

G√∂r serviceresor till en egen dom√§n med separata regler och AI-template.

Bredda datak√§llor (Mercell/Kommers/e-Avrop) med API/RSS f√∂rst, Scrapling som fallback.

Bygg feedback-loop i UI (relevant/taggar) och b√∂rja ‚Äútrimma p√• riktigt‚Äù.

Prompt

Du √§r senior systemarkitekt + upphandlingsspecialist (LOU/LUF/LUK + kollektivtrafik). L√§s SYSTEM_OVERVIEW.md nedan och f√∂resl√• en toppniv√•-f√∂rb√§ttring av appen med fokus p√•: 1) produktdefinitioner (Hogia) och hur de ska modelleras som ‚Äúcapabilities‚Äù f√∂r matchning, 2) hur scoringen ska byggas om till capability-baserad ranking, 3) hur serviceresor (taxi, skolskjuts, sjukresor, f√§rdtj√§nst) ska bli en separat klassificeringsdom√§n, 4) vilka nya datak√§llor i Sverige som ska prioriteras och hur man ska f√∂redra API/RSS √∂ver scraping, 5) exakt vilka nya UI-actions som beh√∂vs f√∂r s√§ljfeedback och hur feedbacken anv√§nds f√∂r att f√∂rb√§ttra matchningen, 6) hur AI-analysen ska paketeras till s√§lj (30 sek summary, kravmatris light, risks, fr√•gor). Output ska vara: A) en prioriterad backlog i 10 punkter, B) ett nytt dataschema (f√§lt + tabeller) f√∂r capability-matching och feedback, C) en reviderad scoring-spec med viktning och exempel, D) en kort plan f√∂r hur vi testar tr√§ffs√§kerhet (precision/recall) utan att bygga tung ML.



Lexis del i projeket

Ja. Det d√§r √§r exakt r√§tt arkitektur.

Men du m√•ste vara h√•rd i designen:

**Lexi = t√§nkpartner och researcher.**
**Upphandlingssystemet = Single Source of Truth (SSOT).**

Inte tv√§rtom.

---

# S√• h√§r ska det se ut mentalt

### üîπ SSOT (Upphandlingsmotorn)

Detta √§r:

* Scrapers (TED + svenska k√§llor)
* Capability-baserad scoring
* Evidence extraction
* Fulltext
* Produkt-fit
* Labels / feedback
* Audit

Den f√•r:

* H√§mta
* Klassificera
* R√§kna
* Spara

Den f√•r INTE:

* Resonera strategiskt
* G√∂ra go/no-go
* T√§nka kreativt

---

### üîπ Lexi

Hon f√•r:

* Resonera
* Prioritera
* Identifiera risker
* F√∂resl√• strategi
* Formulera fr√•gor
* Utmana antaganden

Men:

* Hon f√•r ALDRIG hitta p√• fakta
* Hon f√•r ALDRIG referera till n√•got som inte finns i SSOT
* Hon f√•r ALDRIG √§ndra data utan tool call

---

# Exakt hur du kopplar ihop det

Lexi f√•r bara tillg√•ng till 4 typer av verktyg:

### 1Ô∏è‚É£ L√§s-verktyg (default safe)

* list_high_fit()
* get_procurement(id)
* get_product_fit(id)
* get_evidence(id)

‚Üí Dessa kr√§ver ingen approval.

---

### 2Ô∏è‚É£ Analys-verktyg (semisafe)

* generate_brief(id)
* generate_go_nogo(id)
* generate_risk_matrix(id)
* generate_questions(id)

‚Üí Dessa f√•r skriva i DB men markeras som ‚Äúdraft‚Äù.

---

### 3Ô∏è‚É£ Beslutsverktyg (approval required)

* mark_go()
* mark_no_go()
* assign_owner()
* push_to_crm()

---

### 4Ô∏è‚É£ Externa verktyg (always approval)

* send_email()
* create_calendar_event()
* notify_sales_team()

---

# Hur realtid faktiskt fungerar

Det √§r inte ‚ÄúLexi √∂vervakar allt‚Äù.

Det √§r:

1. Cron/scheduler k√∂r scraper.
2. Ny upphandling > fit 70 triggar event.
3. Event skickas till Lexi.
4. Lexi:

   * H√§mtar SSOT-data
   * Skapar ett 30-sekunders-brief
   * St√§ller EN fr√•ga: ‚ÄúVill du att jag g√∂r go/no-go?‚Äù

Det √§r proaktivitet utan kaos.

---

# Det viktigaste: evidence-first

N√§r Lexi svarar m√•ste hon alltid visa:

* Matchgrad
* 3‚Äì6 evidenscitat
* Vilken capability matchar
* Vilken saknas

Annars tappar du f√∂rtroende.

---

# Den riktiga vinsten h√§r

Det h√§r g√∂r att Lexi inte bara ‚Äú√§r AI‚Äù.

Hon blir:

* S√§ljchefens research-assistent
* KAM-st√∂d
* Upphandlingscoach
* Riskdetektor

Och hon jobbar p√• er strukturerade data, inte internet.

---

# Nu kommer den strategiska fr√•gan

Vill du att:

A) Lexi ska vara reaktiv (du fr√•gar henne)
eller
B) Lexi ska vara proaktiv (hon driver pipeline, pushar, ifr√•gas√§tter)?

B √§r kraftfullare ‚Äì men kr√§ver strikt verktygskontroll och audit.

---

# Tv√• uppgifter (r√§tt ordning)

**Uppgift 1:** Definiera exakt vilka dataf√§lt i SSOT som √§r ‚Äútrusted‚Äù och vilka som √§r ‚Äúderived‚Äù.
**Uppgift 2:** Skriv en kort Lexi-systemprompt som tvingar henne att alltid arbeta evidence-first och aldrig spekulera.

---

# Prompt

Du √§r systemarkitekt f√∂r en AI-assistent (Lexi) som ska fungera som t√§nkpartner och researcher inom offentlig upphandling. Systemet har en Single Source of Truth (SSOT) som inneh√•ller strukturerad upphandlingsdata, produktmatchning och evidens. Designa en arkitektur d√§r Lexi endast f√•r anv√§nda data fr√•n SSOT via definierade read/write tools. Krav: 1) Lexi f√•r aldrig generera fakta som inte kan h√§rledas till SSOT-evidence, 2) alla write-actions ska vara draft tills m√§nniska godk√§nner, 3) proaktiva notifieringar ska triggas av events (t.ex. new_high_fit), 4) varje svar fr√•n Lexi ska inneh√•lla matchgrad + evidenscitat. Leverera: systemprompt, tool-interfaces, approval-policy och event-fl√∂de.

Vill du att vi nu:

1. Definierar Lexis exakta systemprompt
   eller
2. Designar det tekniska event-fl√∂det mellan scraper ‚Üí SSOT ‚Üí Lexi?
